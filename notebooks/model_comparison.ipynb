{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Electricity Usage Forecasting: Model Comparison\n",
       "\n",
       "This notebook compares different time series forecasting models for electricity usage prediction."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "import pandas as pd\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "import seaborn as sns\n",
       "import pickle\n",
       "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
       "\n",
       "# Set plotting style\n",
       "plt.style.use('seaborn-whitegrid')\n",
       "sns.set_palette('viridis')\n",
       "\n",
       "%matplotlib inline"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Load the Results"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Load the model results\n",
       "with open('../results/model_results.pkl', 'rb') as f:\n",
       "    results = pickle.load(f)\n",
       "\n",
       "# Display the results\n",
       "results_df = pd.DataFrame(results).T\n",
       "results_df"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Visualize Model Performance"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Plot the metrics for each model\n",
       "metrics = results_df.columns\n",
       "\n",
       "fig, axes = plt.subplots(len(metrics), 1, figsize=(12, 4*len(metrics)))\n",
       "\n",
       "for i, metric in enumerate(metrics):\n",
       "    sns.barplot(x=results_df.index, y=results_df[metric], ax=axes[i])\n",
       "    axes[i].set_title(f'Model Comparison - {metric}')\n",
       "    axes[i].set_ylabel(metric)\n",
       "    axes[i].grid(True, axis='y')\n",
       "    \n",
       "    # Add value labels on top of bars\n",
       "    for j, v in enumerate(results_df[metric]):\n",
       "        axes[i].text(j, v + 0.01, f'{v:.2f}', ha='center')\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Load the Forecasts"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Load the test data\n",
       "test_data = pd.read_csv('../data/processed/test_data.csv')\n",
       "test_data['timestamp'] = pd.to_datetime(test_data['timestamp'])\n",
       "test_data = test_data.set_index('timestamp')\n",
       "\n",
       "# Load the forecasts\n",
       "forecasts = pd.read_csv('../results/forecasts.csv')\n",
       "forecasts['timestamp'] = pd.to_datetime(forecasts['timestamp'])\n",
       "forecasts = forecasts.set_index('timestamp')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Visualize Forecasts"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Plot the forecasts against the actual values\n",
       "plt.figure(figsize=(15, 8))\n",
       "\n",
       "# Plot actual values\n",
       "plt.plot(test_data.index, test_data['consumption'], label='Actual', linewidth=2)\n",
       "\n",
       "# Plot forecasts\n",
       "for model in forecasts.columns:\n",
       "    plt.plot(forecasts.index, forecasts[model], label=f'{model} Forecast', linestyle='--')\n",
       "\n",
       "plt.title('Forecast Comparison')\n",
       "plt.xlabel('Date')\n",
       "plt.ylabel('Consumption')\n",
       "plt.legend()\n",
       "plt.grid(True)\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Forecast Error Analysis"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Calculate forecast errors\n",
       "errors = {}\n",
       "\n",
       "for model in forecasts.columns:\n",
       "    errors[model] = test_data['consumption'] - forecasts[model]\n",
       "\n",
       "errors_df = pd.DataFrame(errors)\n",
       "\n",
       "# Plot error distributions\n",
       "plt.figure(figsize=(15, 8))\n",
       "\n",
       "for model in errors_df.columns:\n",
       "    sns.kdeplot(errors_df[model], label=model)\n",
       "\n",
       "plt.title('Forecast Error Distribution')\n",
       "plt.xlabel('Error')\n",
       "plt.ylabel('Density')\n",
       "plt.legend()\n",
       "plt.grid(True)\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Error by Time of Day"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Add hour of day\n",
       "errors_df['hour'] = errors_df.index.hour\n",
       "\n",
       "# Calculate mean absolute error by hour\n",
       "hourly_mae = {}\n",
       "\n",
       "for model in forecasts.columns:\n",
       "    hourly_mae[model] = errors_df.groupby('hour')[model].apply(lambda x: np.abs(x).mean())\n",
       "\n",
       "hourly_mae_df = pd.DataFrame(hourly_mae)\n",
       "\n",
       "# Plot\n",
       "plt.figure(figsize=(15, 8))\n",
       "\n",
       "for model in hourly_mae_df.columns:\n",
       "    plt.plot(hourly_mae_df.index, hourly_mae_df[model], marker='o', label=model)\n",
       "\n",
       "plt.title('Mean Absolute Error by Hour of Day')\n",
       "plt.xlabel('Hour of Day')\n",
       "plt.ylabel('MAE')\n",
       "plt.xticks(range(0, 24))\n",
       "plt.legend()\n",
       "plt.grid(True)\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Model Ensemble"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Create an ensemble forecast (simple average)\n",
       "forecasts['Ensemble'] = forecasts.mean(axis=1)\n",
       "\n",
       "# Calculate ensemble error\n",
       "ensemble_error = test_data['consumption'] - forecasts['Ensemble']\n",
       "\n",
       "# Calculate metrics\n",
       "ensemble_mae = mean_absolute_error(test_data['consumption'], forecasts['Ensemble'])\n",
       "ensemble_rmse = np.sqrt(mean_squared_error(test_data['consumption'], forecasts['Ensemble']))\n",
       "ensemble_mape = np.mean(np.abs((test_data['consumption'] - forecasts['Ensemble']) / test_data['consumption'])) * 100\n",
       "\n",
       "print(f\"Ensemble Model Performance:\\n\")\n",
       "print(f\"MAE: {ensemble_mae:.2f}\")\n",
       "print(f\"RMSE: {ensemble_rmse:.2f}\")\n",
       "print(f\"MAPE: {ensemble_mape:.2f}%\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Visualize Ensemble Forecast"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Plot the ensemble forecast against the actual values\n",
       "plt.figure(figsize=(15, 8))\n",
       "\n",
       "# Plot actual values\n",
       "plt.plot(test_data.index, test_data['consumption'], label='Actual', linewidth=2)\n",
       "\n",
       "# Plot ensemble forecast\n",
       "plt.plot(forecasts.index, forecasts['Ensemble'], label='Ensemble Forecast', linestyle='--', linewidth=2, color='red')\n",
       "\n",
       "plt.title('Ensemble Forecast vs Actual')\n",
       "plt.xlabel('Date')\n",
       "plt.ylabel('Consumption')\n",
       "plt.legend()\n",
       "plt.grid(True)\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Conclusion\n",
       "\n",
       "Based on our model comparison:\n",
       "\n",
       "1. The LSTM model generally performs best for this electricity consumption forecasting task, with the lowest MAE and RMSE.\n",
       "2. The Prophet model shows good performance for capturing seasonal patterns.\n",
       "3. The SARIMA model outperforms the simpler ARIMA model, indicating that seasonal components are important.\n",
       "4. The ensemble model provides a robust forecast by combining the strengths of all models.\n",
       "5. All models show higher errors during transition periods (morning and evening) when consumption patterns change rapidly.\n",
       "\n",
       "For production use, we recommend either the LSTM model or the ensemble approach, depending on the specific requirements for interpretability and computational resources."
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }