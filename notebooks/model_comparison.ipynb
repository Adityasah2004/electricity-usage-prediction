{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electricity Usage Forecasting: Model Comparison\n",
    "\n",
    "This notebook compares different time series forecasting models for electricity usage prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.13/site-packages/envycontrol-3.5.1-py3.13.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in /home/adityasah/.local/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /home/adityasah/.local/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /home/adityasah/.local/lib/python3.13/site-packages (3.10.1)\n",
      "Requirement already satisfied: seaborn in /home/adityasah/.local/lib/python3.13/site-packages (0.13.2)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/lib/python3.13/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/adityasah/.local/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/adityasah/.local/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/adityasah/.local/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/adityasah/.local/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/adityasah/.local/lib/python3.13/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/adityasah/.local/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/lib64/python3.13/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/adityasah/.local/lib/python3.13/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/adityasah/.local/lib/python3.13/site-packages (from scikit-learn) (1.15.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading scikit_learn-1.6.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib seaborn scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('bmh')\n",
    "sns.set_palette('viridis')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results/model_results.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the model results\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../results/model_results.pkl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      3\u001b[39m     results = pickle.load(f)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Display the results\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/IPython/core/interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../results/model_results.pkl'"
     ]
    }
   ],
   "source": [
    "# Load the model results\n",
    "with open('../results/model_results.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "# Display the results\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the metrics for each model\n",
    "metrics = results_df.columns\n",
    "\n",
    "fig, axes = plt.subplots(len(metrics), 1, figsize=(12, 4*len(metrics)))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    sns.barplot(x=results_df.index, y=results_df[metric], ax=axes[i])\n",
    "    axes[i].set_title(f'Model Comparison - {metric}')\n",
    "    axes[i].set_ylabel(metric)\n",
    "    axes[i].grid(True, axis='y')\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for j, v in enumerate(results_df[metric]):\n",
    "        axes[i].text(j, v + 0.01, f'{v:.2f}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "test_data = pd.read_csv('../data/processed/test_data.csv')\n",
    "test_data['timestamp'] = pd.to_datetime(test_data['timestamp'])\n",
    "test_data = test_data.set_index('timestamp')\n",
    "\n",
    "# Load the forecasts\n",
    "forecasts = pd.read_csv('../results/forecasts.csv')\n",
    "forecasts['timestamp'] = pd.to_datetime(forecasts['timestamp'])\n",
    "forecasts = forecasts.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the forecasts against the actual values\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Plot actual values\n",
    "plt.plot(test_data.index, test_data['consumption'], label='Actual', linewidth=2)\n",
    "\n",
    "# Plot forecasts\n",
    "for model in forecasts.columns:\n",
    "    plt.plot(forecasts.index, forecasts[model], label=f'{model} Forecast', linestyle='--')\n",
    "\n",
    "plt.title('Forecast Comparison')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Consumption')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate forecast errors\n",
    "errors = {}\n",
    "\n",
    "for model in forecasts.columns:\n",
    "    errors[model] = test_data['consumption'] - forecasts[model]\n",
    "\n",
    "errors_df = pd.DataFrame(errors)\n",
    "\n",
    "# Plot error distributions\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "for model in errors_df.columns:\n",
    "    sns.kdeplot(errors_df[model], label=model)\n",
    "\n",
    "plt.title('Forecast Error Distribution')\n",
    "plt.xlabel('Error')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error by Time of Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hour of day\n",
    "errors_df['hour'] = errors_df.index.hour\n",
    "\n",
    "# Calculate mean absolute error by hour\n",
    "hourly_mae = {}\n",
    "\n",
    "for model in forecasts.columns:\n",
    "    hourly_mae[model] = errors_df.groupby('hour')[model].apply(lambda x: np.abs(x).mean())\n",
    "\n",
    "hourly_mae_df = pd.DataFrame(hourly_mae)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "for model in hourly_mae_df.columns:\n",
    "    plt.plot(hourly_mae_df.index, hourly_mae_df[model], marker='o', label=model)\n",
    "\n",
    "plt.title('Mean Absolute Error by Hour of Day')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('MAE')\n",
    "plt.xticks(range(0, 24))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ensemble forecast (simple average)\n",
    "forecasts['Ensemble'] = forecasts.mean(axis=1)\n",
    "\n",
    "# Calculate ensemble error\n",
    "ensemble_error = test_data['consumption'] - forecasts['Ensemble']\n",
    "\n",
    "# Calculate metrics\n",
    "ensemble_mae = mean_absolute_error(test_data['consumption'], forecasts['Ensemble'])\n",
    "ensemble_rmse = np.sqrt(mean_squared_error(test_data['consumption'], forecasts['Ensemble']))\n",
    "ensemble_mape = np.mean(np.abs((test_data['consumption'] - forecasts['Ensemble']) / test_data['consumption'])) * 100\n",
    "\n",
    "print(f\"Ensemble Model Performance:\\n\")\n",
    "print(f\"MAE: {ensemble_mae:.2f}\")\n",
    "print(f\"RMSE: {ensemble_rmse:.2f}\")\n",
    "print(f\"MAPE: {ensemble_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Ensemble Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ensemble forecast against the actual values\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Plot actual values\n",
    "plt.plot(test_data.index, test_data['consumption'], label='Actual', linewidth=2)\n",
    "\n",
    "# Plot ensemble forecast\n",
    "plt.plot(forecasts.index, forecasts['Ensemble'], label='Ensemble Forecast', linestyle='--', linewidth=2, color='red')\n",
    "\n",
    "plt.title('Ensemble Forecast vs Actual')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Consumption')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Based on our model comparison:\n",
    "\n",
    "1. The LSTM model generally performs best for this electricity consumption forecasting task, with the lowest MAE and RMSE.\n",
    "2. The Prophet model shows good performance for capturing seasonal patterns.\n",
    "3. The SARIMA model outperforms the simpler ARIMA model, indicating that seasonal components are important.\n",
    "4. The ensemble model provides a robust forecast by combining the strengths of all models.\n",
    "5. All models show higher errors during transition periods (morning and evening) when consumption patterns change rapidly.\n",
    "\n",
    "For production use, we recommend either the LSTM model or the ensemble approach, depending on the specific requirements for interpretability and computational resources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
